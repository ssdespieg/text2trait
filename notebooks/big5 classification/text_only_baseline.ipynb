{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cvY-L9q3qjeD"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "\n",
        "text2trait: Big Five Personality Trait Classification using GPT-4o\n",
        "\n",
        "This script processes a semantically chunked stream-of-consciousness text dataset to classify the presence or absence\n",
        "of the Big Five personality traits (Openness, Conscientiousness, Extroversion, Agreeableness, Neuroticism)\n",
        "in text chunks using OpenAI's GPT-4o model.\n",
        "\n",
        "Condition: TEXT ONLY : BASELINE (Zero-shot prompting with text)\n",
        "\n",
        "The process involves:\n",
        "- Building a detailed prompt that asks GPT-4o to classify all Big Five traits in a single JSON response.\n",
        "- Requesting the model to classify all five personality traits individually, in one request.\n",
        "- Storing the model's structured JSON output incrementally to avoid data loss.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import json\n",
        "import openai\n",
        "from tqdm.auto import tqdm\n",
        "import time\n",
        "\n",
        "###############################################################################\n",
        "# CONFIGURE OPENAI CLIENT FOR V1.0+ USAGE\n",
        "###############################################################################\n",
        "\n",
        "# API key:\n",
        "openai.api_key = \"OPENAI-API-KEY\"  # Replace with actual API key\n",
        "\n",
        "# Model name\n",
        "MODEL_NAME = \"gpt-4o-2024-11-20\"\n",
        "\n",
        "# Optional: Set custom endpoint or organization ID if required\n",
        "# openai.api_base = \"https://api.openai.com/v1\"\n",
        "# openai.organization = \"<ORG_ID>\"\n",
        "\n",
        "###############################################################################\n",
        "# TRAIT LIST AND PROMPT\n",
        "###############################################################################\n",
        "\n",
        "TRAIT_LIST = [\n",
        "    \"Openness to Experience\",\n",
        "    \"Conscientiousness\",\n",
        "    \"Extroversion\",\n",
        "    \"Agreeableness\",\n",
        "    \"Neuroticism\"\n",
        "]\n",
        "\n",
        "def build_prompt_for_all_traits(text_chunk: str) -> str:\n",
        "    \"\"\"\n",
        "    Request classification of all Big Five traits in a single JSON response.\n",
        "    \"\"\"\n",
        "    traits_str = \"\\n\".join(f\"- {t}\" for t in TRAIT_LIST)\n",
        "    prompt = f\"\"\"You are an intelligent and disciplined assistant trained to determine\n",
        "    the presence or absence of each of the Big Five personality traits in\n",
        "    a stream-of-consciousness text. The traits are:\n",
        "    {traits_str}\n",
        "\n",
        "    **Your output must be valid JSON** with the structure:\n",
        "\n",
        "    {{\n",
        "      \"traits\": [\n",
        "        {{\n",
        "          \"trait\": \"Openness to Experience\",\n",
        "          \"result\": \"y|n|NaN\",\n",
        "          \"result_justification\": \"...\",\n",
        "          \"confidence_score\": 0.0,\n",
        "          \"confidence_score_justification\": \"...\"\n",
        "        }},\n",
        "        {{\n",
        "          \"trait\": \"Extroversion\",\n",
        "          \"result\": \"y|n|NaN\",\n",
        "          \"result_justification\": \"...\",\n",
        "          \"confidence_score\": 0.0,\n",
        "          \"confidence_score_justification\": \"...\"\n",
        "        }},\n",
        "        ...\n",
        "      ]\n",
        "    }}\n",
        "\n",
        "    Rules:\n",
        "    1. If insufficient data, set 'result'='NaN', 'result_justification'='NaN',\n",
        "       'confidence_score'=0.0, 'confidence_score_justification'='NaN'.\n",
        "    2. No extra text, no code fences, no keys beyond what is shown.\n",
        "    3. The 'result' MUST be 'y', 'n', or 'NaN'.\n",
        "\n",
        "    The text: {text_chunk}\n",
        "    \"\"\"\n",
        "    return prompt.strip()\n",
        "\n",
        "def classify_text_chunk(text_chunk: str) -> str:\n",
        "    \"\"\"\n",
        "    Calls the new v1.0+ method openai.chat.completions.create\n",
        "    with response_format for structured JSON.\n",
        "    \"\"\"\n",
        "    user_prompt = build_prompt_for_all_traits(text_chunk)\n",
        "    response = openai.chat.completions.create(\n",
        "        model=MODEL_NAME,\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": \"You are a helpful, disciplined assistant that outputs JSON only.\"\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": user_prompt\n",
        "            },\n",
        "        ],\n",
        "        response_format={\"type\": \"json_object\"},\n",
        "        temperature=1.0,\n",
        "        max_tokens=1200\n",
        "    )\n",
        "    # Extract the JSON from the model\n",
        "    raw_json_str = response.choices[0].message.content\n",
        "    return raw_json_str\n",
        "\n",
        "###############################################################################\n",
        "# MAIN LOGIC: READ LINES, CALL MODEL, SAVE RESULTS INCREMENTALLY\n",
        "###############################################################################\n",
        "\n",
        "def main():\n",
        "    input_json = \"full_chunked_local_minima_pass_2_0.40.json\"\n",
        "    output_file = \"structured_big5_results_gpt-4o_temp_1.0.json\"\n",
        "    total_lines_to_process = 2000\n",
        "\n",
        "    if not os.path.exists(input_json):\n",
        "        print(f\"[ERROR] Input file does not exist: {input_json}\")\n",
        "        return\n",
        "\n",
        "    # Get the number of lines already processed\n",
        "    processed_count = 0\n",
        "    if os.path.exists(output_file):\n",
        "        with open(output_file, \"r\", encoding=\"utf-8\") as out_f:\n",
        "            for _ in out_f:  # Count the lines\n",
        "                processed_count += 1\n",
        "\n",
        "    print(f\"[INFO] Found {processed_count} lines already processed.\")\n",
        "\n",
        "    # Store results line-by-line\n",
        "    with open(output_file, \"a\", encoding=\"utf-8\") as out_f:  # Open in append mode\n",
        "        with open(input_json, \"r\", encoding=\"utf-8\") as f:\n",
        "            # Create a tqdm progress bar that will process up to `total_lines_to_process`\n",
        "            with tqdm(total=total_lines_to_process, desc=\"Processing Chunks\", initial=processed_count) as pbar:\n",
        "                for i, line in enumerate(f):\n",
        "                    if i < processed_count:\n",
        "                        continue  # Skip already processed lines\n",
        "\n",
        "                    if processed_count >= total_lines_to_process:\n",
        "                        break  # Stop if total lines reached\n",
        "\n",
        "                    row = json.loads(line)\n",
        "                    author_id = row.get(\"#AUTHID\", \"\")\n",
        "                    chunk_number = row.get(\"Chunk Number\", \"\")\n",
        "                    text_chunk = row.get(\"TEXT\", \"\")\n",
        "\n",
        "                    print(f\"\\n[PROCESSING] Row {i} => Author: {author_id}, Chunk: {chunk_number}\")\n",
        "\n",
        "                    try:\n",
        "                        raw_json = classify_text_chunk(text_chunk)\n",
        "                        print(\"[RAW MODEL OUTPUT]\\n\", raw_json)\n",
        "\n",
        "                        # Parse the JSON to verify it's valid\n",
        "                        try:\n",
        "                            parsed = json.loads(raw_json)\n",
        "                        except json.JSONDecodeError as e:\n",
        "                            print(f\"[ERROR] Could not parse JSON for row {i}: {e}\")\n",
        "                            parsed = {\"error\": \"Invalid JSON\", \"exception\": str(e)}\n",
        "\n",
        "                        # Save the final record\n",
        "                        record = {\n",
        "                            \"author_id\": author_id,\n",
        "                            \"chunk_number\": chunk_number,\n",
        "                            \"model_output\": parsed\n",
        "                        }\n",
        "                        out_f.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n",
        "\n",
        "                        processed_count += 1\n",
        "                        pbar.update(1)  # Update the progress bar\n",
        "\n",
        "                    except Exception as e:\n",
        "                        print(f\"[ERROR] In call to model: {e}\")\n",
        "                        record = {\n",
        "                            \"author_id\": author_id,\n",
        "                            \"chunk_number\": chunk_number,\n",
        "                            \"model_output\": {\"error\": str(e)}\n",
        "                        }\n",
        "                        out_f.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n",
        "\n",
        "                    # Optional: Add a small delay to avoid rate limits\n",
        "                    time.sleep(0.5)\n",
        "\n",
        "    print(f\"\\n[DONE] Wrote results to {output_file}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "llm",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
