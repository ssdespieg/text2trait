{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gtKoXV4-DWjw"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# WSL path to project directory\n",
        "wsl_path = \"/mnt/g/My Drive/Sophia/MSC thesis/final_datasets\"\n",
        "\n",
        "# Change current working directory to the WSL path\n",
        "os.chdir(wsl_path)\n",
        "\n",
        "# Print the current working directory to verify the change\n",
        "print(\"Current working directory:\", os.getcwd())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1NvOjymFDWjx"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import openai\n",
        "from tqdm.auto import tqdm\n",
        "import time\n",
        "\n",
        "###############################################################################\n",
        "# CONFIGURE OPENAI CLIENT FOR V1.0+ USAGE\n",
        "###############################################################################\n",
        "\n",
        "# API key:\n",
        "openai.api_key = \"OPENAI-API-KEY\"  # Replace with actual API key\n",
        "\n",
        "# Model name\n",
        "MODEL_NAME = \"gpt-4o-2024-11-20\"\n",
        "\n",
        "###############################################################################\n",
        "# TRAIT LIST AND PROMPT\n",
        "###############################################################################\n",
        "\n",
        "TRAIT_LIST = [\n",
        "    \"Openness to Experience\",\n",
        "    \"Conscientiousness\",\n",
        "    \"Extroversion\",\n",
        "    \"Agreeableness\",\n",
        "    \"Neuroticism\"\n",
        "]\n",
        "\n",
        "def load_semantic_features(filepath: str) -> dict:\n",
        "    \"\"\"Loads semantic features from a JSON file and creates a lookup dictionary.\"\"\"\n",
        "    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
        "        data = {}\n",
        "        for line in f:\n",
        "            try:\n",
        "                record = json.loads(line)\n",
        "                author_id = record['author_id']\n",
        "                chunk_number = record['chunk_number']\n",
        "\n",
        "                # Check for the presence of 'model_output' and 'features' keys\n",
        "                if 'model_output' in record and 'features' in record['model_output']:\n",
        "                    features = record['model_output']['features']\n",
        "                    key = (author_id, chunk_number)\n",
        "                    data[key] = features\n",
        "                else:\n",
        "                    print(f\"Warning: Missing 'model_output' or 'features' in record: {record}\")\n",
        "            except json.JSONDecodeError as e:\n",
        "                print(f\"Error decoding JSON: {e}\")\n",
        "                print(f\"Problematic line: {line.strip()}\")\n",
        "    return data\n",
        "\n",
        "def build_prompt_for_all_traits(text_chunk: str, semantic_features_list: list) -> str:\n",
        "    \"\"\"\n",
        "    Request classification of all Big Five traits in a single JSON response, including semantic features.\n",
        "    \"\"\"\n",
        "    traits_str = \"\\n\".join(f\"- {t}\" for t in TRAIT_LIST)\n",
        "    sanitized_text_chunk = text_chunk.replace(\"{\", \"{{\").replace(\"}\", \"}}\")\n",
        "\n",
        "    # Create a formatted string of semantic features\n",
        "    semantic_features_str = \"\"\n",
        "    for feature in semantic_features_list:\n",
        "        feature_name = feature['feature']\n",
        "        reasoning_steps = '\\\\n'.join(feature['reasoning_steps'])\n",
        "        result = feature['result']\n",
        "        result_justification = feature['result_justification']\n",
        "        confidence_score = feature['confidence_score']\n",
        "        confidence_score_justification = feature['confidence_score_justification']\n",
        "\n",
        "        semantic_features_str += f\"  - **{feature_name}:**\\\\n\"\n",
        "        semantic_features_str += f\"    - Reasoning Steps: {reasoning_steps}\\\\n\"\n",
        "        semantic_features_str += f\"    - Result: {result}\\\\n\"\n",
        "        semantic_features_str += f\"    - Result Justification: {result_justification}\\\\n\"\n",
        "        semantic_features_str += f\"    - Confidence Score: {confidence_score}\\\\n\"\n",
        "        semantic_features_str += f\"    - Confidence Score Justification: {confidence_score_justification}\\\\n\"\n",
        "\n",
        "    prompt = f\"\"\"You are an intelligent and disciplined assistant trained to determine\n",
        "    the presence or absence of each of the Big Five personality traits in\n",
        "    a stream-of-consciousness text. The traits are: {traits_str}\n",
        "\n",
        "    **You will be provided with the text and semantic features extracted from the text. Consider these inputs in your analysis.**\n",
        "\n",
        "    **Your task is to reason through each trait step-by-step, explaining how the text and the relevant semantic features provide evidence (or lack thereof) for each trait before determining the final result and confidence score.**\n",
        "\n",
        "    **Your output must be valid JSON** with the structure:\n",
        "\n",
        "    {{\n",
        "      \"traits\": [\n",
        "        {{\n",
        "          \"trait\": \"Openness to Experience\",\n",
        "          \"reasoning_steps\": [\n",
        "            \"...\"\n",
        "          ],\n",
        "          \"result\": \"y|n|NaN\",\n",
        "          \"result_justification\": \"...\",\n",
        "          \"confidence_score\": 0.0,\n",
        "          \"confidence_score_justification\": \"...\"\n",
        "        }},\n",
        "        {{\n",
        "          \"trait\": \"Conscientiousness\",\n",
        "          \"reasoning_steps\": [\n",
        "            \"...\"\n",
        "          ],\n",
        "          \"result\": \"y|n|NaN\",\n",
        "          \"result_justification\": \"...\",\n",
        "          \"confidence_score\": 0.0,\n",
        "          \"confidence_score_justification\": \"...\"\n",
        "        }},\n",
        "        ...\n",
        "      ]\n",
        "    }}\n",
        "\n",
        "    Rules:\n",
        "    1. For each trait, reason step-by-step as described, then provide the final evaluation in the JSON format.\n",
        "    2. Consider the provided semantic features in your analysis and reasoning.\n",
        "    3. If insufficient data, set 'result'='NaN', 'result_justification'='NaN',\n",
        "       'confidence_score'=0.0, 'confidence_score_justification'='NaN'.\n",
        "    4. No extra text, no code fences, no keys beyond what is shown.\n",
        "    5. The 'result' must be 'y', 'n', or 'NaN'.\n",
        "    6. Provide detailed justifications for the reasoning, results, and confidence scores.\n",
        "\n",
        "    The text: {sanitized_text_chunk}\n",
        "\n",
        "    The semantic features: {semantic_features_str}\n",
        "    \"\"\"\n",
        "    return prompt.strip()\n",
        "\n",
        "def classify_text_chunk(text_chunk: str, semantic_features: list) -> str:\n",
        "    \"\"\"\n",
        "    Calls the new v1.0+ method openai.chat.completions.create\n",
        "    with response_format for structured JSON.\n",
        "    \"\"\"\n",
        "    user_prompt = build_prompt_for_all_traits(text_chunk, semantic_features)\n",
        "    response = openai.chat.completions.create(\n",
        "        model=MODEL_NAME,\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": \"You are a helpful, disciplined assistant that outputs JSON only.\"\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": user_prompt\n",
        "            },\n",
        "        ],\n",
        "        response_format={\"type\": \"json_object\"},\n",
        "        temperature=1.0,\n",
        "        max_tokens=2000\n",
        "    )\n",
        "    raw_json_str = response.choices[0].message.content\n",
        "    return raw_json_str\n",
        "\n",
        "###############################################################################\n",
        "# MAIN LOGIC: READ LINES, CALL MODEL, SAVE RESULTS INCREMENTALLY\n",
        "###############################################################################\n",
        "\n",
        "def main():\n",
        "    input_json = \"full_chunked_local_minima_pass_2_0.40.json\"\n",
        "    semantic_features_file = \"semantic_feature_extraction/cot-structured_feature_extraction_openai_gpt-4o_temp_1.0.json\"\n",
        "    output_file = f\"big5_classification/big5_semantic_features_classification/semfeat_cot_big5_openai_gpt-4o_temp_1.0.json\"\n",
        "    total_lines_to_process = 2000\n",
        "\n",
        "    if not os.path.exists(input_json):\n",
        "        print(f\"[ERROR] Input file does not exist: {input_json}\")\n",
        "        return\n",
        "\n",
        "    if not os.path.exists(semantic_features_file):\n",
        "        print(f\"[ERROR] Semantic features file does not exist: {semantic_features_file}\")\n",
        "        return\n",
        "\n",
        "    semantic_features_lookup = load_semantic_features(semantic_features_file)\n",
        "\n",
        "    if os.path.exists(output_file):\n",
        "        with open(output_file, \"r\", encoding=\"utf-8\") as f:\n",
        "            processed_count = sum(1 for _ in f)\n",
        "        print(f\"[INFO] Found {processed_count} lines already processed.\")\n",
        "    else:\n",
        "        processed_count = 0\n",
        "\n",
        "    with open(output_file, \"a\", encoding=\"utf-8\") as out_f:\n",
        "        with open(input_json, \"r\", encoding=\"utf-8\") as f:\n",
        "            with tqdm(total=total_lines_to_process, desc=\"Processing Chunks\", initial=processed_count) as pbar:\n",
        "                for i, line in enumerate(f):\n",
        "                    if i >= processed_count:\n",
        "                        row = json.loads(line)\n",
        "                        author_id = row.get(\"#AUTHID\", \"\")\n",
        "                        chunk_number = row.get(\"Chunk Number\", \"\")\n",
        "                        text_chunk = row.get(\"TEXT\", \"\")\n",
        "\n",
        "                        print(f\"\\n[PROCESSING] Row {i} => Author: {author_id}, Chunk: {chunk_number}\")\n",
        "\n",
        "                        sem_features_key = (author_id, chunk_number)\n",
        "                        semantic_features = semantic_features_lookup.get(sem_features_key, [])\n",
        "\n",
        "                        try:\n",
        "                            raw_json = classify_text_chunk(text_chunk, semantic_features)\n",
        "                            print(\"[RAW MODEL OUTPUT]\\n\", raw_json)\n",
        "\n",
        "                            try:\n",
        "                                parsed = json.loads(raw_json)\n",
        "                            except json.JSONDecodeError as e:\n",
        "                                print(f\"[ERROR] Could not parse JSON for row {i}: {e}\")\n",
        "                                parsed = {\"error\": \"Invalid JSON\", \"exception\": str(e)}\n",
        "\n",
        "                            record = {\n",
        "                                \"author_id\": author_id,\n",
        "                                \"chunk_number\": chunk_number,\n",
        "                                \"model_output\": parsed\n",
        "                            }\n",
        "                            out_f.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n",
        "                            out_f.flush()\n",
        "                            processed_count += 1\n",
        "                            pbar.update(1)\n",
        "\n",
        "                        except Exception as e:\n",
        "                            print(f\"[ERROR] In call to model: {e}\")\n",
        "                            record = {\n",
        "                                \"author_id\": author_id,\n",
        "                                \"chunk_number\": chunk_number,\n",
        "                                \"model_output\": {\"error\": str(e)}\n",
        "                            }\n",
        "                            out_f.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n",
        "                            out_f.flush()\n",
        "\n",
        "                    if processed_count >= total_lines_to_process:\n",
        "                        break\n",
        "\n",
        "    print(f\"\\n[DONE] Wrote results to {output_file}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "llm3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}