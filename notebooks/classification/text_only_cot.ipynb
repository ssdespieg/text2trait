{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9gi8b19soVqx"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# WSL path to project directory\n",
        "wsl_path = \"/mnt/g/My Drive/Sophia/MSC thesis/final_datasets\"\n",
        "\n",
        "# Change current working directory to the WSL path\n",
        "os.chdir(wsl_path)\n",
        "\n",
        "# Print the current working directory to verify the change\n",
        "print(\"Current working directory:\", os.getcwd())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0YNFiM6HoVqz"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import openai\n",
        "from tqdm.auto import tqdm\n",
        "import time\n",
        "\n",
        "###############################################################################\n",
        "# CONFIGURE OPENAI CLIENT FOR V1.0+ USAGE\n",
        "###############################################################################\n",
        "\n",
        "# API key:\n",
        "openai.api_key = \"OPENAI-API-KEY\"  # Replace with actual API key\n",
        "\n",
        "# Model name\n",
        "MODEL_NAME = \"gpt-4o-2024-11-20\"\n",
        "\n",
        "###############################################################################\n",
        "# TRAIT LIST AND PROMPT\n",
        "###############################################################################\n",
        "\n",
        "TRAIT_LIST = [\n",
        "    \"Openness to Experience\",\n",
        "    \"Conscientiousness\",\n",
        "    \"Extroversion\",\n",
        "    \"Agreeableness\",\n",
        "    \"Neuroticism\"\n",
        "]\n",
        "\n",
        "def build_prompt_for_all_traits(text_chunk: str) -> str:\n",
        "    \"\"\"\n",
        "    Request classification of all Big Five traits in a single JSON response.\n",
        "    \"\"\"\n",
        "    traits_str = \"\\n\".join(f\"- {t}\" for t in TRAIT_LIST)\n",
        "    prompt = f\"\"\"You are an intelligent and disciplined assistant trained to determine\n",
        "    the presence or absence of each of the Big Five personality traits in\n",
        "    a stream-of-consciousness text. The traits are:\n",
        "    {traits_str}\n",
        "\n",
        "    **Your task is to reason through each trait step-by-step, explaining how the text provides evidence (or lack thereof) for each trait before determining the final result and confidence score.**\n",
        "\n",
        "    **Your output must be valid JSON** with the structure:\n",
        "\n",
        "    {{\n",
        "      \"traits\": [\n",
        "        {{\n",
        "          \"trait\": \"Openness to Experience\",\n",
        "          \"reasoning_steps\": [\n",
        "            \"...\"\n",
        "          ],\n",
        "          \"result\": \"y|n|NaN\",\n",
        "          \"result_justification\": \"...\",\n",
        "          \"confidence_score\": 0.0,\n",
        "          \"confidence_score_justification\": \"...\"\n",
        "        }},\n",
        "        {{\n",
        "          \"trait\": \"Conscientiousness\",\n",
        "          \"reasoning_steps\": [\n",
        "            \"...\"\n",
        "          ],\n",
        "          \"result\": \"y|n|NaN\",\n",
        "          \"result_justification\": \"...\",\n",
        "          \"confidence_score\": 0.0,\n",
        "          \"confidence_score_justification\": \"...\"\n",
        "        }},\n",
        "        ...\n",
        "      ]\n",
        "    }}\n",
        "\n",
        "    Rules:\n",
        "    1. For each trait, reason step-by-step as described, then provide the final evaluation in the JSON format.\n",
        "    2. If insufficient data, set 'result'='NaN', 'result_justification'='NaN',\n",
        "       'confidence_score'=0.0, 'confidence_score_justification'='NaN'.\n",
        "    3. No extra text, no code fences, no keys beyond what's shown.\n",
        "    4. The 'result' MUST be 'y', 'n', or 'NaN'.\n",
        "\n",
        "    The text: {text_chunk}\n",
        "    \"\"\"\n",
        "    return prompt.strip()\n",
        "\n",
        "def classify_text_chunk(text_chunk: str) -> str:\n",
        "    \"\"\"\n",
        "    Calls the new v1.0+ method openai.chat.completions.create\n",
        "    with response_format for structured JSON.\n",
        "    \"\"\"\n",
        "    user_prompt = build_prompt_for_all_traits(text_chunk)\n",
        "    response = openai.chat.completions.create(\n",
        "        model=MODEL_NAME,\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": \"You are a helpful, disciplined assistant that outputs JSON only.\"\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": user_prompt\n",
        "            },\n",
        "        ],\n",
        "        temperature=1.0,\n",
        "        max_tokens=1200\n",
        "    )\n",
        "    # Extract the JSON from the model\n",
        "    raw_json_str = response.choices[0].message.content\n",
        "    return raw_json_str\n",
        "\n",
        "###############################################################################\n",
        "# MAIN LOGIC: READ LINES, CALL MODEL, SAVE RESULTS INCREMENTALLY\n",
        "###############################################################################\n",
        "\n",
        "def main():\n",
        "    input_json = \"full_chunked_local_minima_pass_2_0.40.json\"\n",
        "    output_file = f\"big5_classification/big5_text_only_classification/text_only_cot_big5_results_gpt-4o_temp_1.0.json\"\n",
        "    total_lines_to_process = 2000\n",
        "\n",
        "    # Ensure the output file path is absolute for clarity\n",
        "    output_file = os.path.abspath(output_file)\n",
        "\n",
        "    # Check if input file exists\n",
        "    if not os.path.exists(input_json):\n",
        "        print(f\"[ERROR] Input file does not exist: {input_json}\")\n",
        "        return\n",
        "\n",
        "    print(f\"[INFO] Output file path: {output_file}\")\n",
        "\n",
        "    # Get the number of lines already processed\n",
        "    processed_count = 0\n",
        "    if os.path.exists(output_file):\n",
        "        with open(output_file, \"r\", encoding=\"utf-8\") as out_f:\n",
        "            for _ in out_f:  # Count the lines\n",
        "                processed_count += 1\n",
        "\n",
        "    print(f\"[INFO] Found {processed_count} lines already processed.\")\n",
        "\n",
        "    # Start processing lines\n",
        "    with open(output_file, \"a\", encoding=\"utf-8\") as out_f:  # Open in append mode\n",
        "        with open(input_json, \"r\", encoding=\"utf-8\") as f:\n",
        "            # Create a tqdm progress bar\n",
        "            with tqdm(total=total_lines_to_process, desc=\"Processing Chunks\", initial=processed_count) as pbar:\n",
        "                for i, line in enumerate(f):\n",
        "                    if i < processed_count:\n",
        "                        continue  # Skip already processed lines\n",
        "\n",
        "                    if processed_count >= total_lines_to_process:\n",
        "                        break  # Stop if total lines reached\n",
        "\n",
        "                    row = json.loads(line)\n",
        "                    author_id = row.get(\"#AUTHID\", \"\")\n",
        "                    chunk_number = row.get(\"Chunk Number\", \"\")\n",
        "                    text_chunk = row.get(\"TEXT\", \"\")\n",
        "\n",
        "                    print(f\"\\n[PROCESSING] Row {i} => Author: {author_id}, Chunk: {chunk_number}\")\n",
        "\n",
        "                    try:\n",
        "                        raw_json = classify_text_chunk(text_chunk)\n",
        "                        print(\"[RAW MODEL OUTPUT]\\n\", raw_json)\n",
        "\n",
        "                        # Parse the JSON to verify it's valid\n",
        "                        try:\n",
        "                            parsed = json.loads(raw_json)\n",
        "                        except json.JSONDecodeError as e:\n",
        "                            print(f\"[ERROR] Could not parse JSON for row {i}: {e}\")\n",
        "                            parsed = {\"error\": \"Invalid JSON\", \"exception\": str(e)}\n",
        "\n",
        "                        # Save the final record\n",
        "                        record = {\n",
        "                            \"author_id\": author_id,\n",
        "                            \"chunk_number\": chunk_number,\n",
        "                            \"model_output\": parsed\n",
        "                        }\n",
        "                        out_f.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n",
        "                        out_f.flush()  # Ensure immediate write to disk\n",
        "                        os.fsync(out_f.fileno())  # Force OS writes to disk\n",
        "\n",
        "                        print(f\"[INFO] Wrote record for Row {i} to {output_file}\")\n",
        "                        processed_count += 1\n",
        "                        pbar.update(1)  # Update the progress bar\n",
        "\n",
        "                    except Exception as e:\n",
        "                        print(f\"[ERROR] In call to model: {e}\")\n",
        "                        record = {\n",
        "                            \"author_id\": author_id,\n",
        "                            \"chunk_number\": chunk_number,\n",
        "                            \"model_output\": {\"error\": str(e)}\n",
        "                        }\n",
        "                        out_f.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n",
        "                        out_f.flush()\n",
        "                        os.fsync(out_f.fileno())  # Force OS writes to disk\n",
        "\n",
        "                        print(f\"[INFO] Wrote error record for Row {i} to {output_file}\")\n",
        "\n",
        "                    # Add a small delay to avoid rate limits\n",
        "                    time.sleep(0.5)\n",
        "\n",
        "    print(f\"\\n[DONE] Wrote results to {output_file}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "llm5",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}