{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Semantic Feature Confidence Analysis\n",
        "\n",
        "This script analyzes confidence scores from GPT-4o's semantic feature extraction results\n",
        "on semantically chunked stream-of-consciousness text data. It examines the model's confidence in classifying\n",
        "five key psycholinguistic features:\n",
        "\n",
        "1. Cognitive Flexibility\n",
        "2. Narrative and Discourse Coherence\n",
        "3. Emotional Tone\n",
        "4. Self-Reflection Depth\n",
        "5. Analytical Thinking\n",
        "\n",
        "Process Overview:\n",
        "- Loads structured feature extraction results from JSON\n",
        "- Processes and aggregates confidence scores across all features\n",
        "- Generates statistical summaries and visualizations\n",
        "- Identifies notable examples of high/low confidence patterns (for report)\n",
        "\n",
        "The analysis helps understand:\n",
        "- Distribution of confidence scores across different features\n",
        "- Patterns in model uncertainty\n",
        "- Feature-specific confidence variations\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from typing import List, Dict, Any\n",
        "\n",
        "###############################################################################\n",
        "# CONSTANTS AND CONFIGURATIONS\n",
        "###############################################################################\n",
        "# Feature list for confidence analysis\n",
        "CONFIDENCE_FEATURES = [\n",
        "    'Cognitive Flexibility',\n",
        "    'Narrative and Discourse Coherence',\n",
        "    'Emotional Tone',\n",
        "    'Self-Reflection Depth',\n",
        "    'Analytical Thinking'\n",
        "]\n",
        "\n",
        "# Data path for feature extraction results\n",
        "DATA_PATH = '/content/drive/MyDrive/MSC thesis/final_datasets/semantic_feature_extraction/cot-structured_feature_extraction_openai_gpt-4o_temp_1.0.json'\n",
        "\n",
        "###############################################################################\n",
        "# DATA LOADING AND PROCESSING\n",
        "###############################################################################\n",
        "CONFIDENCE_FEATURES = [\n",
        "    'Cognitive Flexibility',\n",
        "    'Narrative and Discourse Coherence',\n",
        "    'Emotional Tone',\n",
        "    'Self-Reflection Depth',\n",
        "    'Analytical Thinking'\n",
        "]\n",
        "\n",
        "###############################################################################\n",
        "# FEATURE DATA EXTRACTION\n",
        "###############################################################################\n",
        "    \"\"\"\n",
        "    Extract feature data from model outputs into a structured format.\n",
        "    \"\"\"\n",
        "    feature_data = []\n",
        "\n",
        "    for index, row in df.iterrows():\n",
        "        try:\n",
        "            if isinstance(row['model_output'], dict) and 'features' in row['model_output']:\n",
        "                for feature in row['model_output']['features']:\n",
        "                    feature_data.append({\n",
        "                        'author_id': row['author_id'],\n",
        "                        'chunk_number': row['chunk_number'],\n",
        "                        'feature': feature['feature'],\n",
        "                        'result': feature['result'],\n",
        "                        'confidence_score': float(feature['confidence_score'])\n",
        "                    })\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing row {index}: {e}\")\n",
        "            continue\n",
        "\n",
        "    return pd.DataFrame(feature_data)\n",
        "\n",
        "###############################################################################\n",
        "# CONFIDENCE SCORE ANALYSIS\n",
        "###############################################################################\n",
        "    \"\"\"\n",
        "    Create pivot table for confidence scores analysis.\n",
        "    \"\"\"\n",
        "    return features_df.pivot(\n",
        "        index=['author_id', 'chunk_number'],\n",
        "        columns='feature',\n",
        "        values='confidence_score'\n",
        "    ).reset_index()\n",
        "\n",
        "def print_confidence_statistics(confidence_df: pd.DataFrame) -> None:\n",
        "    \"\"\"\n",
        "    Print summary statistics for confidence scores.\n",
        "    \"\"\"\n",
        "    summary_stats = confidence_df[CONFIDENCE_FEATURES].describe()\n",
        "    summary_stats.loc['median'] = confidence_df[CONFIDENCE_FEATURES].median()\n",
        "    print(\"\\nSummary statistics for confidence scores:\")\n",
        "    print(summary_stats)\n",
        "\n",
        "    for feature in CONFIDENCE_FEATURES:\n",
        "        mean_score = confidence_df[feature].mean()\n",
        "        std_score = confidence_df[feature].std()\n",
        "        median_score = confidence_df[feature].median()\n",
        "        print(f\"\\nFeature: {feature}\")\n",
        "        print(f\"Mean: {mean_score:.2f}, Median: {median_score:.2f}, Std: {std_score:.2f}\")\n",
        "\n",
        "###############################################################################\n",
        "# VISUALIZATION FUNCTIONS\n",
        "###############################################################################\n",
        "    \"\"\"\n",
        "    Generate boxplot visualization of confidence scores.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    sns.boxplot(data=confidence_df[CONFIDENCE_FEATURES], width=0.6, palette=\"Set2\")\n",
        "    plt.title(\"Confidence Scores Distribution by Feature\", fontsize=14)\n",
        "    plt.ylabel(\"Confidence Score\", fontsize=12)\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "    n_size = len(confidence_df)\n",
        "    plt.text(0.95, 0.95, f'n = {n_size}',\n",
        "             transform=plt.gca().transAxes,\n",
        "             ha='right', va='top',\n",
        "             bbox=dict(facecolor='white', edgecolor='none', alpha=0.7))\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def plot_confidence_distributions(confidence_df: pd.DataFrame) -> None:\n",
        "    \"\"\"\n",
        "    Generate distribution plots for confidence scores.\n",
        "    \"\"\"\n",
        "    colors = sns.color_palette(\"Set2\")\n",
        "    fig = plt.figure(figsize=(15, 10))\n",
        "    n_size = len(confidence_df)\n",
        "\n",
        "    for i, (col, color) in enumerate(zip(CONFIDENCE_FEATURES, colors), 1):\n",
        "        ax = plt.subplot(3, 2, i)\n",
        "        sns.histplot(confidence_df[col], kde=True, bins=15, color=color)\n",
        "        plt.title(f\"Distribution of {col}\")\n",
        "        plt.xlabel(\"Confidence Score\")\n",
        "\n",
        "        plt.text(0.95, 0.95, f'n = {n_size}',\n",
        "                transform=ax.transAxes,\n",
        "                ha='right', va='top',\n",
        "                bbox=dict(facecolor='white', edgecolor='none', alpha=0.7))\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "###############################################################################\n",
        "# EXAMPLE FINDING AND ANALYSIS\n",
        "###############################################################################\n",
        "                                 low_threshold: float = 0.3,\n",
        "                                 high_threshold: float = 0.7,\n",
        "                                 specific_high: float = 0.9) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Find samples with mixed confidence scores.\n",
        "    \"\"\"\n",
        "    return df[(df[CONFIDENCE_FEATURES].max(axis=1) > high_threshold) &\n",
        "             (df[CONFIDENCE_FEATURES].min(axis=1) < low_threshold) &\n",
        "             (df[CONFIDENCE_FEATURES] == specific_high).any(axis=1)]\n",
        "\n",
        "def find_specific_example(df: pd.DataFrame, author_id: str, chunk_number: int) -> None:\n",
        "    \"\"\"\n",
        "    Find and display specific example by author ID and chunk number.\n",
        "    \"\"\"\n",
        "    specific_row = df[(df['author_id'] == author_id) & (df['chunk_number'] == chunk_number)]\n",
        "    if not specific_row.empty:\n",
        "        print(f\"\\nDetails for author '{author_id}' in chunk {chunk_number}:\")\n",
        "        print(specific_row.T.to_string(header=False))\n",
        "    else:\n",
        "        print(f\"\\nNo data found for author '{author_id}' in chunk {chunk_number}\")\n",
        "\n",
        "###############################################################################\n",
        "# MAIN EXECUTION\n",
        "###############################################################################\n",
        "    \"\"\"\n",
        "    Main execution function for confidence score analysis.\n",
        "    \"\"\"\n",
        "    # Extract and process feature data\n",
        "    features_df = extract_feature_data(df)\n",
        "    confidence_df = create_confidence_pivot(features_df)\n",
        "\n",
        "    # Generate statistics and visualizations\n",
        "    print_confidence_statistics(confidence_df)\n",
        "    plot_confidence_boxplots(confidence_df)\n",
        "    plot_confidence_distributions(confidence_df)\n",
        "\n",
        "    # Author-level analysis\n",
        "    author_means = confidence_df.groupby('author_id')[CONFIDENCE_FEATURES].mean()\n",
        "    print(\"\\nAverage confidence scores per author:\")\n",
        "    print(author_means.head())\n",
        "\n",
        "    # Find example cases\n",
        "    mixed_samples = find_mixed_confidence_examples(confidence_df)\n",
        "    if not mixed_samples.empty:\n",
        "        print(\"\\nExample of mixed confidence scores:\")\n",
        "        print(mixed_samples.iloc[0])\n",
        "\n",
        "    # Find specific example\n",
        "    find_specific_example(confidence_df, '1997_891831', 7)\n",
        "\n",
        "def load_feature_data(filepath: str) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Load feature extraction data from JSON file.\n",
        "\n",
        "    Args:\n",
        "        filepath: Path to the JSON lines file containing feature extraction results\n",
        "\n",
        "    Returns:\n",
        "        DataFrame containing the loaded data\n",
        "    \"\"\"\n",
        "    try:\n",
        "        return pd.read_json(filepath, orient='records', lines=True)\n",
        "    except Exception as e:\n",
        "        raise Exception(f\"Error loading data from {filepath}: {e}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Load feature extraction results\n",
        "\n",
        "    df = load_feature_data(DATA_PATH)\n",
        "    main(df)"
      ],
      "metadata": {
        "id": "KNnKKFfMf7-C"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}